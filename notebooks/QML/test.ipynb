{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Tenorflow-Quantum and Cirq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import tensorflow as tf\n",
    "# import tensorflow_quantum as tfq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset and required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Data Processing tools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# QML tools\n",
    "import tensorflow_quantum as tfq\n",
    "import cirq\n",
    "import sympy\n",
    "\n",
    "# Visualization Tools\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cirq version 1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Print the version of cirq and tfq that we will use\n",
    "print(\"TensorFlow-Quantum version {}\".format(tfq.__version__))\n",
    "print(\"Cirq version {}\".format(cirq.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Fashion MNIST dataset from keras\n",
    "from tensorflow.keras.datasets import fashion_mnist as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
    "\n",
    "\n",
    "print(\"The shape of the X_train is {}\".format( X_train.shape))\n",
    "print(\"The shape of the y_train is {}\".format(y_train.shape))\n",
    "print(\"The shape of the X_test is {}\".format(X_test.shape))\n",
    "print(\"The shape of the y_test is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(x, y):\n",
    "  \"\"\"\n",
    "  Helper Function to filter the dataset\n",
    "  \"\"\"\n",
    "  #filter the data using labels\n",
    "  keep = (y == 5) | (y == 9)\n",
    "  x, y = x[keep], y[keep]\n",
    "\n",
    "  # convert labels to boolean\n",
    "  # y = True if y==5\n",
    "  # y = False if y==9\n",
    "  y = y == 5\n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the train set\n",
    "X_train, y_train = filter_data(X_train, y_train)\n",
    "\n",
    "#Filter the test_set\n",
    "X_test, y_test = filter_data(X_test, y_test)\n",
    "\n",
    "# Let's have a look at the shapes of train and test data\n",
    "print(\"The shape of the X_train is {}\".format( X_train.shape))\n",
    "print(\"The shape of the y_train is {}\".format(y_train.shape))\n",
    "print(\"The shape of the X_test is {}\".format(X_test.shape))\n",
    "print(\"The shape of the y_test is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's have a look at the first image from our X_train and the \n",
    "# corresponding label from y_train\n",
    "print(\"The First Image has the label {}\".format(y_train[0]))\n",
    "plt.imshow(X_train[0])\n",
    "plt.colorbar()\n",
    "plt.title('Visualization of the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the colorbar in the above visualization, it is clear that we have grayscale images in the dataset and hence their values range from 0 to 255. However, we would like to scale these pixel values in our dataset so that the values range from 0 to 1. This will help us to converge our CNN training faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the train and test image data\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's again have a look at the first image from our X_train and\n",
    "#see if we have successfully normalized the datasets\n",
    "plt.imshow(X_train[0])\n",
    "plt.colorbar()\n",
    "plt.title('Visualization of the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Before proceeding, we need to reshape our images in the dataset\n",
    "X_train = X_train.reshape(X_train.shape[0], *(28,28,1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscaling the images\n",
    "X_train = tf.image.resize(X_train, (2,2)).numpy()\n",
    "X_test = tf.image.resize(X_test, (2,2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's again have a look at the first image from our resized X_train\n",
    "plt.imshow(X_train[0,:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Visualization of the Resized Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training fdataset into train and validation datasets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.15, random_state=0)\n",
    "\n",
    "print(\"The shape of the X_train is {}\".format(X_train.shape))\n",
    "print(\"The shape of the y_train is {}\".format(y_train.shape))\n",
    "print(\"The shape of the X_valid is {}\".format(X_valid.shape))\n",
    "print(\"The shape of the y_valid is {}\".format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Encoding\n",
    "Steps involved in Data Encoding:\n",
    "\n",
    "Processing pixel values for binary encoding\n",
    "\n",
    "Converting Cirq Circuits to tfq tensors\n",
    "\n",
    "Step 1: Processing Pixel Values for Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLattening the images\n",
    "X_train = X_train.reshape(X_train.shape[0], *(1,4,1))\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], *(1,4,1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(1,4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's have a look on the first example\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(X,threshold=0.5):\n",
    "  \"\"\"\n",
    "  Encodes the given datset to use binary encoding\n",
    "\n",
    "  Parameters:\n",
    "  X(array) : Image data to be processed for encoding\n",
    "  threshold(float): Threshold for binary encoding, 0.5 by default\n",
    "\n",
    "  Returns:\n",
    "  encoded_images(array): Binary encoded Image Data\n",
    "\n",
    "  \"\"\" \n",
    "  encoded_images = list()\n",
    "  for image in X:\n",
    "    # pixel value is 1 if it's greater than threshold or else zero\n",
    "    encoded_image = [1 if j>threshold else 0 for j in image[0]]\n",
    "    encoded_images.append(encoded_image)\n",
    "  return np.array(encoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = binary_encode(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, Let's have a look on the first example again\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the X_train is {}\".format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circuit_from_image(encoded_image):\n",
    "  \"\"\"\n",
    "  Returns a circuit for given encoded image\n",
    "\n",
    "  Parameters:\n",
    "  encoded_image (array): Encoded Image\n",
    "\n",
    "  Returns:\n",
    "  circuit (cirq.Circuit object): cirq circuit\n",
    "  \"\"\"\n",
    "  qubits = cirq.GridQubit.rect(2,2)\n",
    "  circuit = cirq.Circuit()\n",
    "  for i, pixel in enumerate(encoded_image):\n",
    "    if pixel:\n",
    "      circuit.append(cirq.X(qubits[i]))\n",
    "  return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [create_circuit_from_image(encoded_image) for encoded_image in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the circuit for the first image\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Converting Cirq Circuits to tfq Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfq = tfq.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing X_valid and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = binary_encode(X_valid)\n",
    "X_test = binary_encode(X_test)\n",
    "     \n",
    "\n",
    "X_valid = [create_circuit_from_image(encoded_image) for encoded_image in X_valid]\n",
    "X_test = [create_circuit_from_image(encoded_image) for encoded_image in X_test]\n",
    "     \n",
    "\n",
    "X_valid_tfq = tfq.convert_to_tensor(X_valid)\n",
    "X_test_tfq = tfq.convert_to_tensor(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
